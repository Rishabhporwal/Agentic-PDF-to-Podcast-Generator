# LLM Provider Configuration
# Choose: 'anthropic' or 'ollama'
LLM_PROVIDER=ollama

# Anthropic Configuration (if using Anthropic)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Ollama Configuration (if using Ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3
